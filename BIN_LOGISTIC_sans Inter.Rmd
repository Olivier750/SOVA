---
output:
  html_document: default
  pdf_document: default
---

# REGRESSION BINAIRE : FISSURATION AVEC RISQUE DE RUPTURE vs NON RUPTURE 
# SANS LES INTERACTIONS

## 1. Creation des bases d'etude :

```{r}
BASE_Bin_TRAIN <- read.table("BASE_Bin_TRAIN.csv",sep=";",header=T)
BASE_Bin_TEST  <- read.table("BASE_Bin_TEST.csv",sep=";",header=T)
```

Création des 10 folds sur TRAIN avec repartition homogéne des modalités 0 et 1
```{r}
# separation des reponses :
X<-BASE_Bin_TRAIN ;rownames(X)<-NULL
X_0 <-X[which(X$Class_Binaire==0),] ;rownames(X_0)<-NULL
X_1 <-X[which(X$Class_Binaire==1),] ;rownames(X_1)<-NULL

# creation fonction qui recupere 1/10 de la base aleatoirement : 
CROSS<-function(X){
  set.seed(1444)
  ID<-sample(1:nrow(X),nrow(X)) # rangement des lignes dans le desordre
  a<- seq(1,nrow(X),round((nrow(X)/10))+1) # selection de 1 ligne sur 10
  X$fold<-10
  for (i in 1:9){
    X$fold[ID[a[i]:(a[i+1]-1)]]<-i
  }
  return(X)
}

# creation de la base de travail :
X_0<-CROSS(X_0)
X_1<-CROSS(X_1)
X_fin<-rbind(X_0,X_1)
X_fin<-X_fin[order(X_fin$fold),]
rownames(X_fin)<-NULL
table (X_fin$fold) 
```

## 2. Etude du modele sur TRAIN par cross validation

```{r}
# initialisation :
performances <- c()
Faux_Positif <- c()
Faux_negatif <- c()

for (j in seq(0.3, 0.5, 0.05) ) {

  # les 10 fold sur train :
  for (i in 1:10){
    # Train qui contient 9 blocs
    training_set <- X_fin[X_fin$fold != i,]
    # test qui contient 1 bloc
    testing_set <-  X_fin[X_fin$fold == i,]
    # modele 
    BIN_LOG1.fit <- glm(Class_Binaire ~ ANNEE_POSE+AGE+VITESSE +UIC +TRAIN +Profil +TYPE_RAYON_COURBE, data=training_set, family="binomial")
    BIN_LOG1.probs <- predict(BIN_LOG1.fit, testing_set, type = "response", allow.new.levels = TRUE)
    
    BIN_LOG1.pred <- rep("0", length(BIN_LOG1.probs))
    BIN_LOG1.pred[BIN_LOG1.probs > j] = "1"
    # matrice de confusion
    K <- table(BIN_LOG1.pred,testing_set$Class_Binaire)
    K <- addmargins(table(BIN_LOG1.pred,testing_set$Class_Binaire))
    # calcul du taux de bien classé, et des erreurs FP et FN
    CLASSE_OK<-(mean(BIN_LOG1.pred == testing_set$Class_Binaire))
    TFP <- K[2,1]/K[3,1]
      TFN <- K[1,2]/K[3,2]
    # Ajouter à la liste ->> à la fin on obtient 10 : on les moyenne
    performances[i] <- CLASSE_OK
    Faux_Positif[i] <- TFP
    Faux_negatif[i] <- TFN
  }
    performances
    Faux_Positif
    Faux_negatif
  # Moyenne des erreurs :
  print(paste("Pour une proba de ",j))  
  print(c('Performance' = mean(performances)))
  print(c('TFP' = mean(Faux_Positif)))
  print(c('TFN' = mean(Faux_negatif)))
}
```

## 3. Construction du modéle sur TRAIN avec proba de 0.4

Le modéle :
```{r}
BIN_LOG1.fit <- glm(Class_Binaire ~ ANNEE_POSE+AGE+VITESSE +UIC +TRAIN +Profil +TYPE_RAYON_COURBE, data=BASE_Bin_TRAIN, family="binomial")
summary(BIN_LOG1.fit)
```
Vérification de la significativité des variables :
```{r}
anova(BIN_LOG1.fit, test = "Chisq")
```
Elles sont toutes significatives.

Validation sur TEST :
```{r}
BIN_LOG1.probs <- predict(BIN_LOG1.fit, BASE_Bin_TEST, type = "response")

#Evaluation de l'erreur de prédiction du modèle sur les données de test én prenant un seuil de 0.5 : proba que l'on transforme en reponse predites si > ou < à 50% :   
BIN_LOG1.pred <- rep("0", length(BIN_LOG1.probs))
BIN_LOG1.pred[BIN_LOG1.probs > .4] = "1"

# Calcul de la moyenne des bien predit sur le test :  
Perf<-(mean(BIN_LOG1.pred == BASE_Bin_TEST$Class_Binaire) )

# Matrice de confusion associé au modèle
confusion <- table(BIN_LOG1.pred, BASE_Bin_TEST$Class_Binaire)

# Utilisation de la fonction `addmargins` pour ajouter les sommes de chaque ligne et colonne.
confusion <- addmargins(table(BIN_LOG1.pred, BASE_Bin_TEST$Class_Binaire))
confusion

# Calcul du taux de Faux positifs (TFP) : 
TFP <- confusion[2,1]/confusion[3,1]

# Calcul du taux de Faux negatifs (TFN) : 
TFN <- confusion[1,2]/confusion[3,2]

# Affichage :
  print(c('Performance' = Perf))
  print(c('TFP' = TFP))
  print(c('TFN' = TFN))
```
# Courbe ROC sur le TEST :
# Permet de visualiser la performance d’un classificateur binaire lorsque ce seuil varie. Elles représentent graphiquement le taux de vrais positifs én fonction du taux de faux positifs.

```{r}
#install.packages("Epi")
library(Epi)
ROC(test = BIN_LOG1.probs,
	stat = BASE_Bin_TEST$Class_Binaire,
	data = BASE_Bin_TEST, plot = "ROC", MI=F)
```









